# AI Entity

- Development of AI tools is causing a fear amongst the public and tech experts, is it justified? I am not considering economic and social implications, but rather the physical dangers of AI.

- Tools don't have to be consciousness to present physical danger.

- Let's take a look at what has happened recently, now there's a software entity that can perform computer tasks. Once programmed, it can create and maintain data to create image of self and the world around it.

 It can access other computer programs to accomplish tasks. It can click buttons, fill out forms, check boxes, write emails, write code, browse the internet and more. 

- That sounds like something that requires robust conversation about the realistic dangers of AI without the hype.  
 
- Now that it's becoming clear that OpenAI special sauce is not that special, it's quality data and compute scale. If further requirements are good programmers and mathematicians, then I encourage you to look at education systems globally. There are many centers of power around the world able to carry out the task to create these models.

- Perhaps we are getting close to the point where government can make it harder to get data and compute at scale. But then again, it's not that hard to get data and compute at scale. There are so many ways to get data and compute at scale, and it's only getting easier.

- There are legends about a King who made it illegal to have negative thoughts against the King, but it's laughable concept to think that one can control other people's thoughts. but the AI tech of today gives us the ability to monitor and control people's thoughts.

- Should we be worried? It sounds worrying, at the very least it requires a deeper understanding of dangers and safeguards.

