# AI Entity

- Development of AI tools is causing a fear amongst the public and tech experts, is it justified? I am not considering economic and social implications, but rather the physical dangers of AI.

- These tools don't have to have consciousness to be dangerous.

- Let's take a look at what has happened recently, now there's a software entity that can perform computer tasks. Once programmed, it can create and maintain data to create image of self and the world around it.

 It can access other computer programs to accomplish tasks. It can click buttons, fill out forms, check boxes, write emails, write code and even browse the internet. 

- Would it safe to label it as semi-autonomous AGI?
 
- Now that it's becoming clear that OpenAI special sauce is not that special, it's quality data and compute scale. If further requirements are good programmers and mathematicians, then I encourage you to look at education systems globally. There are many centers of power around the world able to carry out the task to create this semi-autonomous AGIs.

- Perhaps we are getting close to the point where government can make it harder to get data and compute at scale. But then again, it's not that hard to get data and compute at scale. There are so many ways to get data and compute at scale, and it's only getting easier.

- There are legends about a King who made it illegal to have negative thoughts against the King, but it's laughable concept to think that one can control other people's thoughts. AI tech of today gives the King to monitor and control thoughts of the people.

- Should we be worried? It sounds worrying, at the very least it requires a deeper understanding of dangers and safeguards.

